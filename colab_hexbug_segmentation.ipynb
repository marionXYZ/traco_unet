{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "xtTFL4CIqLg3",
        "0rll8uD7rUmN",
        "kupEpEostUZc",
        "MACQI_yX-3iN",
        "7cYDOADaEWdF"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hexbug detection using U-Net\n",
        "In this Colab notebook, we will train U-Net to segment the heads of hexbugs."
      ],
      "metadata": {
        "id": "dVbajBAGpRnn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparations"
      ],
      "metadata": {
        "id": "xtTFL4CIqLg3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use Colab's free GPU**\n",
        "\n",
        "* Click \"Runtime\" tab\n",
        "* Select \"change runtime type\"\n",
        "* Select GPU"
      ],
      "metadata": {
        "id": "1uCCZrEEsRa9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get data into Colab**\n",
        "* Zip folder \"train_data\"\n",
        "* Create and zip folder \"recorded_data\"\n",
        "* Copy the zip-file to GoogleDrive\n",
        "* Connect to GoogleDrive and unzip the folder:"
      ],
      "metadata": {
        "id": "tDTcdttcpklL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2GMJX5wopqT"
      },
      "outputs": [],
      "source": [
        "# Connect to GoogleDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ******\n",
        "# TO DO: Adjust the path (on your GoogleDrive) to the folders to unzip\n",
        "# ******\n",
        "!unzip \"drive/MyDrive/Colab Notebooks/TRACO_Budapest/train_data.zip\"\n",
        "!unzip \"drive/MyDrive/Colab Notebooks/TRACO_Budapest/recorded_data.zip\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the videos and annotations are there\n",
        "import os\n",
        "os.listdir(\"train_data\")[:5]"
      ],
      "metadata": {
        "id": "G41wleejqkoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install useful packages for image segmentation\n",
        "!pip install albumentations\n",
        "!pip install segmentation-models\n",
        "%env SM_FRAMEWORK=tf.keras"
      ],
      "metadata": {
        "id": "mTZJxdxekhbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages\n",
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from ipywidgets import interact\n",
        "\n",
        "from keras import layers\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import load_model\n",
        "from keras.utils import Sequence\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import albumentations as A\n",
        "\n",
        "from segmentation_models.losses import dice_loss, binary_focal_loss\n",
        "from segmentation_models.metrics import iou_score"
      ],
      "metadata": {
        "id": "pIeAOreohZPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the data"
      ],
      "metadata": {
        "id": "0rll8uD7rUmN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DataGenerator**\n",
        "\n",
        "Since we have a lot of training data and the memory in Colab is limited, we created a generator.\n",
        "The DataGenerator loads one batch of data at a time during the training. It also takes care of preprocessing the images."
      ],
      "metadata": {
        "id": "67iy1iu60z_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator(Sequence):\n",
        "  def __init__(self, paths, image_shape=(128, 128), batch_size=32, shuffle=False, augment=None):\n",
        "    self.paths = paths\n",
        "    self.image_shape = image_shape\n",
        "    self.batch_size = batch_size\n",
        "    self.shuffle = shuffle\n",
        "    self.augment = augment\n",
        "\n",
        "    self.image_paths = [p for p in paths if p.endswith(\"img.png\")]\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def __len__(self):\n",
        "    # Returns number of baches\n",
        "    return len(self.image_paths) // self.batch_size\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # Get one batch of data\n",
        "    batch_indexes = self.indexes[idx * self.batch_size:(idx+1) * self.batch_size]\n",
        "    X, y = self._generate_data(batch_indexes)\n",
        "    return X, y\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    # Set up indexes\n",
        "    self.indexes = np.arange(len(self.image_paths))\n",
        "    if self.shuffle:\n",
        "      np.random.shuffle(self.indexes)\n",
        "\n",
        "  def _generate_data(self, batch_indexes):\n",
        "    # Generate one batch\n",
        "    X = np.zeros((self.batch_size, *self.image_shape, 3))\n",
        "    y = np.zeros((self.batch_size, *self.image_shape, 1))\n",
        "\n",
        "    for i, batch_idx in enumerate(batch_indexes):\n",
        "\n",
        "      img_path = self.image_paths[batch_idx]\n",
        "      mask_path = img_path.replace(\"img\", \"mask\")\n",
        "\n",
        "      # Load image\n",
        "      img = cv2.imread(img_path)\n",
        "      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "      # Load mask\n",
        "      mask = cv2.imread(mask_path)\n",
        "      mask = mask[:,:,0]\n",
        "\n",
        "      # Resize\n",
        "      if img.shape[0] != self.image_shape[0]:\n",
        "        img = cv2.resize(img, self.image_shape, interpolation=cv2.INTER_LINEAR)\n",
        "        mask = cv2.resize(mask, self.image_shape, interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "      # ***************\n",
        "      # Optional TO DO: Apply data augmentation (Hint: Use package \"albumentations\")\n",
        "      # ***************\n",
        "\n",
        "\n",
        "      # Add to stack of frames and masks\n",
        "      X[i, ] = img\n",
        "      y[i, ] = mask[..., None]\n",
        "\n",
        "    X = X.astype('float32') / 255.0\n",
        "    y = y.astype('float32') / 255.0  # Mask will contain zeros and ones\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "GmbGflV3Xioy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's try our DataGenerator**"
      ],
      "metadata": {
        "id": "bOnCRzGb1plx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get paths and set up a generator\n",
        "train_paths = [\"train_data/\" + f for f in os.listdir(\"train_data\")]\n",
        "gen = DataGenerator(train_paths, image_shape=(128, 128), batch_size=256, shuffle=True)"
      ],
      "metadata": {
        "id": "Zc3mHO481JQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get first batch from the generator and display it\n",
        "for x, y in gen:\n",
        "  print(x.shape) # images\n",
        "  print(y.shape) # masks\n",
        "  break\n",
        "\n",
        "def show_frame_and_mask(i):\n",
        "    plt.subplot(121)\n",
        "    plt.imshow(x[i])\n",
        "    plt.subplot(122)\n",
        "    plt.imshow(y[i], cmap=\"gray\")\n",
        "    plt.show()\n",
        "\n",
        "interact(show_frame_and_mask, i=(0, 32))"
      ],
      "metadata": {
        "id": "cf3txKNL12YZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Build and train U-Net"
      ],
      "metadata": {
        "id": "kupEpEostUZc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Original U-Net paper:**\n",
        "\n",
        "Ronneberger, O., Fischer, P., & Brox, T. (2015, October). U-net: Convolutional networks for biomedical image segmentation. *In International Conference on Medical image computing and computer-assisted intervention (pp. 234-241)*. Springer, Cham. [Link](https://arxiv.org/abs/1505.04597)"
      ],
      "metadata": {
        "id": "r72QVVHx3NR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv(x, num_filters):\n",
        "  \"\"\" Conv block with two convolutional layers\"\"\"\n",
        "\n",
        "  x = layers.Conv2D(filters=num_filters, kernel_size=3, padding=\"same\")(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "  x = layers.Conv2D(filters=num_filters, kernel_size=3, padding=\"same\")(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Activation(\"relu\")(x)\n",
        "  return x\n",
        "\n",
        "def build_unet(filters, input_shape):\n",
        "  \"\"\"Returns U-Net model\"\"\"\n",
        "\n",
        "    # Input layer\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    e1 = conv(inputs, filters)\n",
        "    p1 = layers.MaxPool2D((2, 2))(e1)\n",
        "\n",
        "    e2 = conv(p1, filters * 2)\n",
        "    p2 = layers.MaxPool2D((2, 2))(e2)\n",
        "\n",
        "    e3 = conv(p2, filters * 4)\n",
        "    p3 = layers.MaxPool2D((2, 2))(e3)\n",
        "\n",
        "    e4 = conv(p3, filters * 8)\n",
        "    p4 = layers.MaxPool2D((2, 2))(e4)\n",
        "\n",
        "    # Bottleneck\n",
        "    b1 = conv(p4, filters * 16)\n",
        "\n",
        "    # Decoder\n",
        "    d1 = layers.UpSampling2D()(b1)\n",
        "    d1 = layers.Concatenate()([d1, e4])\n",
        "    d1 = conv(d1, filters * 8)\n",
        "\n",
        "    d2 = layers.UpSampling2D()(d1)\n",
        "    d2 = layers.Concatenate()([d2, e3])\n",
        "    d2 = conv(d2, filters * 4)\n",
        "\n",
        "    d3 = layers.UpSampling2D()(d2)\n",
        "    d3 = layers.Concatenate()([d3, e2])\n",
        "    d3 = conv(d3, filters * 2)\n",
        "\n",
        "    d4 = layers.UpSampling2D()(d3)\n",
        "    d4 = layers.Concatenate()([d4, e1])\n",
        "    d4 = conv(d4, filters)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = layers.Conv2D(\n",
        "        filters=1,\n",
        "        kernel_size=1,\n",
        "        padding=\"same\",\n",
        "        activation=\"sigmoid\"\n",
        "    )(d4)\n",
        "\n",
        "    return Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "aqF9SB--tbZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training**\n",
        "\n",
        "Now, we can set up U-Net for training. We will use a loss function called \"dice_loss\" and the metric \"iou_score\". They are from the segmentation-models package, see: https://segmentation-models.readthedocs.io/en/latest/api.html#losses"
      ],
      "metadata": {
        "id": "5sWyy2O73oQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build U-Net\n",
        "unet = build_unet(filters=8, input_shape=(128, 128, 3))\n",
        "unet.compile(optimizer=Adam(learning_rate=1e-2), loss=dice_loss, metrics=[iou_score])"
      ],
      "metadata": {
        "id": "JBAOizt_tzuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_paths = [\"train_data/\" + f for f in os.listdir(\"train_data\")]\n",
        "\n",
        "# Split data for training and validation\n",
        "train_paths, val_paths = train_test_split(train_paths, test_size=0.2)\n",
        "\n",
        "# Set up generators\n",
        "train_gen = DataGenerator(train_paths, image_shape=(128, 128), batch_size=256, shuffle=True)\n",
        "val_gen = DataGenerator(val_paths, image_shape=(128, 128), batch_size=256, shuffle=False)"
      ],
      "metadata": {
        "id": "IPTRLft_12KH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "history = unet.fit(train_gen, validation_data=val_gen, epochs=200)\n",
        "\n",
        "# ******\n",
        "# TO DO: Adjust the path (on your GoogleDrive) for saving the trained model\n",
        "# ******\n",
        "unet.save(\"/content/drive/MyDrive/Colab Notebooks/TRACO_Budapest/trained_traco_unet.h5\")"
      ],
      "metadata": {
        "id": "R-8l128vt66J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot IoU score over epochs\n",
        "plt.plot(history.history[\"iou_score\"], label=\"training\")\n",
        "plt.plot(history.history[\"val_iou_score\"], label=\"validation\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"IoU\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Lurm64Mpb5wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display some predictions for the validation images\n",
        "for x, y in val_gen:\n",
        "  predictions = unet.predict(x)\n",
        "  break\n",
        "\n",
        "def show_frame_and_prediction(i):\n",
        "    plt.subplot(121)\n",
        "    plt.imshow(x[i])\n",
        "    plt.subplot(122)\n",
        "    plt.imshow(predictions[i], cmap=\"gray\")\n",
        "    plt.show()\n",
        "\n",
        "interact(show_frame_and_prediction, i=(0, 32))"
      ],
      "metadata": {
        "id": "CicaX-6rFoAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of filters for U-Net, the learning rate, and number of epochs are examples for **hyperparameters**. To improve the performance of U-Net, you can try changing these and comparing the results."
      ],
      "metadata": {
        "id": "kuDoeszK9wZ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check the predictions for you own recorded video!"
      ],
      "metadata": {
        "id": "MACQI_yX-3iN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ******\n",
        "# TO DO: Set up a DataGenerator for your recorded hexbug video\n",
        "# ******\n",
        "\n",
        "# ******\n",
        "# TO DO: Load the trained U-Net model\n",
        "# ******\n",
        "\n",
        "# ******\n",
        "# TO DO: Display the frames with predictions. You can use the function \"show_frame_and_predictions\"\n",
        "# ******"
      ],
      "metadata": {
        "id": "4ssf_qry--GZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert predicted masks back to coordinates"
      ],
      "metadata": {
        "id": "7cYDOADaEWdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ******\n",
        "# TO DO: Find individual heads of hexbugs in the predicted masks\n",
        "# ******\n",
        "\n",
        "# ******\n",
        "# TO DO: Get the center coordinate of each head\n",
        "# ******"
      ],
      "metadata": {
        "id": "-rVFRzjQEVuS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}